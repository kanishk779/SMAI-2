{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to implement Logistic Regression from scratch in this question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You are provided with the dataset of sign language digits. Implement logistic regression from scratch to classify the images provided in the dataset. Load the dataset and perform splitting into training and test sets with 70:30 ratio randomly using test train split.\n",
    "2. Plot a diagram for the sigmoid function. This is used for binary classi\u0000cation. How do you modify it for multilabel dataset classification problems? State and Explain the methods used.\n",
    "3. Use both one vs all and one vs one method for the above problem statement purpose.\n",
    "4. Also get results using Log Reg from scikit learn.\n",
    "5. Report accuracy score, Confusion matrix and any other metrics you feel useful and Compare the results - from all the three.\n",
    "\n",
    "\n",
    "\n",
    "[BONUS]\n",
    "6. Display few pictures with their predicted and original labels \n",
    "7. Do the results differ? State the reasons why it is so.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset link : \n",
    "https://iiitaphyd-my.sharepoint.com/:f:/g/personal/apurva_jadhav_students_iiit_ac_in/Eictt5_qmoxNqezgQQiMWeIBph4sxlfA6jWAJNPnV2SF9Q?e=mQmYN0 \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_l = np.load(\"X.npy\") # image\n",
    "y_l = np.load(\"Y.npy\") # label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2062, 64, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2062, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x : 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "class LinearRegression:\n",
    "    def __init__(self, train_data, Y):\n",
    "        self.data = train_data  # It is assumed that data is normalized and shuffled (rows, cols)\n",
    "        self.Y = Y[:, np.newaxis]\n",
    "        self.b = np.random.randn()\n",
    "        print(self.data.shape)\n",
    "        self.cols = self.data.shape[1]\n",
    "        self.rows = self.data.shape[0]\n",
    "        self.weights = np.random.randn(self.cols, 1)  # Initialising weights to 1, shape (cols, 1)\n",
    "        self.num_iterations = 100\n",
    "        self.learning_rate = 0.0001\n",
    "        self.batch_size = 50\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "        \n",
    "    def calc_mini_batches(self):\n",
    "        new_data = np.hstack((self.data, self.Y))\n",
    "        np.random.shuffle(new_data)\n",
    "    \n",
    "        rem = self.rows % self.batch_size\n",
    "        num = self.rows // self.batch_size\n",
    "        till = self.batch_size * num\n",
    "        if num > 0:\n",
    "            dd = np.array(np.vsplit(new_data[ :till, :], num))\n",
    "            X_batch = dd[:, :, :-1]\n",
    "            Y_batch = dd[:, :, -1]\n",
    "        \n",
    "        if rem != 0:\n",
    "            curr_batch = new_data[till: , :]\n",
    "            diff = self.batch_size - rem\n",
    "            temp = np.zeros((diff, self.cols+1)) # appending with zeros so that the sizes can be matched\n",
    "            curr_batch = np.concatenate((curr_batch, temp))[np.newaxis, :, :]\n",
    "            if num > 0:\n",
    "                X_batch = np.concatenate((X_batch, curr_batch[:, :, :-1]))\n",
    "                Y_batch = np.concatenate((Y_batch, curr_batch[:, :, -1]))\n",
    "            else:\n",
    "                X_batch = curr_batch[:, :, :-1]\n",
    "                Y_batch = curr_batch[:, :, -1]\n",
    "            \n",
    "        return X_batch, Y_batch\n",
    "\n",
    "    def update_weights(self, X, Y):\n",
    "        Y_predicted = np.dot(X, self.weights) + self.b  # Remember that X has data stored along the row for one sample\n",
    "        Y_predicted = self.sigmoid(Y_predicted) \n",
    "        gradient = np.dot(np.transpose(X), Y_predicted - Y)\n",
    "        self.b = self.b - np.sum(Y_predicted - Y)\n",
    "        self.weights = self.weights - (self.learning_rate * gradient) # vector subtraction\n",
    "    \n",
    "    def print_error(self):\n",
    "        Y_Predicted = self.sigmoid(self.predict(self.data))\n",
    "        mask = self.Y == 1\n",
    "        mask \n",
    "        val = np.sum((Y_Predicted - self.Y) ** 2) / self.rows\n",
    "        print(val/1000)\n",
    "    \n",
    "    def gradient_descent(self):\n",
    "        for j in range(self.num_iterations):\n",
    "            X, Y = self.calc_mini_batches()\n",
    "            num_batches = X.shape[0]\n",
    "            for i in range(num_batches):\n",
    "                self.update_weights(X[i, :, :], Y[i, :][:, np.newaxis])  # update the weights\n",
    "            if j%20 == 0:\n",
    "                self.print_error()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # X is 2 dimensional array, samples along the rows\n",
    "        return np.dot(X, self.weights) + self.b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
