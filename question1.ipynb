{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpWQigP0msj9"
   },
   "source": [
    "**Part 1:** \n",
    "\n",
    "Use the **Fashion-MNIST** dataset for this question.\n",
    "\n",
    "1) Load the dataset and perform splitting into training and validation sets with 70:30 ratio.\n",
    "\n",
    "> Do we need to normalise data? [If so Does it make any difference?]\n",
    "\n",
    "2) Implement the K Means algorithm. You need to find the optimal number of clusters using the\n",
    "    elbow method and silhouette method. \n",
    "\n",
    "3) Define the initial clustersâ€™ centroids using:</br>\n",
    "> i) Forgy</br>\n",
    "\n",
    "> ii) Random Partition\n",
    "\n",
    "4) Experiment with different distance measures[Euclidean distance, Manhattan distance].\n",
    "\n",
    "5) Plot the error vs number of clusters graph while using the elbow method and silhouette \n",
    "    method. Report the optimal number of clusters found.\n",
    "\n",
    "6) Report the training and the validation accuracy and Compare your trained model with a model trained by the scikit-learn\n",
    "\n",
    "7) Visualize the dataset to depict the clusters formed. #Prefer T-SNE\n",
    "\n",
    "8) Implement K-means++, and repeat task 1 to task 7 again.</br>\n",
    "</br>\n",
    "</br>\n",
    "</br>\n",
    "</br>\n",
    "**Part 2:**\n",
    "</br>\n",
    "In this task, you will perform operations on `[data.csv](https://drive.google.com/file/d/15NPkfXFoTkiRBlcI4ffe_Lp_BFOyf8UY/view?usp=sharing)`, data.csv is a  latent space representation of  Fashion-MNIST, before doing this task please read about latent space representation.\n",
    "\n",
    "9) Load the data.csv file and apply Kmeans and Kmeans++, You need to find the optimal number of clusters using the elbow method and silhouette method.\n",
    "\n",
    "10) Visualize the dataset to depict the clusters formed. # Prefer T-SNE\n",
    "\n",
    "11) From these experiments(Part 1 and Part 2), compare accuracy or error, and report which one is better and why?\n",
    "</br>\n",
    "</br>\n",
    "**Note:** If the model takes a lot of time to train you can use MiniBatchKMeans.\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GYAN\n",
    "Silhouette method calculates score for each point. (Refer wikipedia for more info)\n",
    "after calculating for each point take the average.\n",
    "Commonly used initialization methods are Forgy and Random Partition.[10] The Forgy method randomly chooses k observations from the dataset and uses these as the initial means. The Random Partition method first randomly assigns a cluster to each observation and then proceeds to the update step, thus computing the initial mean to be the centroid of the cluster's randomly assigned points. The Forgy method tends to spread the initial means out, while Random Partition places all of them close to the center of the data set. The Random Partition method is generally preferable for algorithms such as the k-harmonic means and fuzzy k-means. For expectation maximization and standard k-means algorithms, the Forgy method of initialization is preferable.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
    "assert isinstance(ds, tf.data.Dataset)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yY8uMDe9quTE"
   },
   "outputs": [],
   "source": [
    "#implement elbow method from scratch\n",
    "def elbow():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "32x9M36qq2fO"
   },
   "outputs": [],
   "source": [
    "#implement silhouette method from scratch\n",
    "def silhouette():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "AW0iiyC6qDlb"
   },
   "outputs": [],
   "source": [
    "#implement Kmeans from scratch\n",
    "class Kmeans:\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "h4dn0bULqg1I"
   },
   "outputs": [],
   "source": [
    "#implement Kmeans++ from scratch\n",
    "class Kmeansplusplus:\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "6j7nYmipmrC6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-14180a0a50cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "from tf.keras.datasets import fashion_mnist\n",
    "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
